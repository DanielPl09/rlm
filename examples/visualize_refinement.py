"""
Visualize the incremental refinement process showing how hypothesis evolves.
Creates a visual diagram showing each step of the refinement.
"""

import os
import sys
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from rlm.utils.context_slicer import ContextSlicer
from rlm.utils.anthropic_client import AnthropicClient
import textwrap


def wrap_text(text, width=60):
    """Wrap text to specified width."""
    return '\n'.join(textwrap.wrap(text, width))


def create_ascii_visualization(test_name, query, slices_info, hypothesis_evolution):
    """
    Create ASCII art visualization of the refinement process.

    Args:
        test_name: Name of the test
        query: Original query
        slices_info: List of (slice_id, finding) tuples
        hypothesis_evolution: List of hypothesis versions
    """
    width = 80

    print("\n" + "="*width)
    print(f"INCREMENTAL REFINEMENT VISUALIZATION: {test_name}")
    print("="*width)

    # Query
    print("\n‚îå" + "‚îÄ"*(width-2) + "‚îê")
    print("‚îÇ" + f" QUERY: {query}".ljust(width-2) + "‚îÇ")
    print("‚îî" + "‚îÄ"*(width-2) + "‚îò")

    # Initial state
    print("\n" + "‚îå" + "‚îÄ"*(width-2) + "‚îê")
    print("‚îÇ" + " HYPOTHESIS v0 (Initial)".ljust(width-2) + "‚îÇ")
    print("‚îú" + "‚îÄ"*(width-2) + "‚î§")
    for line in wrap_text(hypothesis_evolution[0], width-4).split('\n'):
        print("‚îÇ " + line.ljust(width-3) + "‚îÇ")
    print("‚îî" + "‚îÄ"*(width-2) + "‚îò")

    # Process each slice
    for i, ((slice_id, finding), new_hypothesis) in enumerate(zip(slices_info, hypothesis_evolution[1:]), 1):
        print("\n" + " "*30 + "‚Üì")
        print(" "*20 + "‚îå" + "‚îÄ"*40 + "‚îê")
        print(" "*20 + f"‚îÇ  PROCESS SLICE {i}/{len(slices_info)}: {slice_id[:30].ljust(30)}‚îÇ")
        print(" "*20 + "‚îî" + "‚îÄ"*40 + "‚îò")

        # Show finding from this slice
        print("\n" + "‚îå" + "‚îÄ"*(width-2) + "‚îê")
        print("‚îÇ" + f" üîµ sub_RLM Query Result from {slice_id}:".ljust(width-2) + "‚îÇ")
        print("‚îú" + "‚îÄ"*(width-2) + "‚î§")
        for line in wrap_text(finding, width-4).split('\n')[:3]:  # Show first 3 lines
            print("‚îÇ " + line.ljust(width-3) + "‚îÇ")
        if len(finding) > width*3:
            print("‚îÇ " + "...".ljust(width-3) + "‚îÇ")
        print("‚îî" + "‚îÄ"*(width-2) + "‚îò")

        print("\n" + " "*30 + "‚Üì")
        print(" "*25 + "üîÑ REFINE")
        print(" "*30 + "‚Üì")

        # Show refined hypothesis
        print("\n" + "‚îå" + "‚îÄ"*(width-2) + "‚îê")
        print("‚îÇ" + f" HYPOTHESIS v{i} (After {slice_id})".ljust(width-2) + "‚îÇ")
        print("‚îú" + "‚îÄ"*(width-2) + "‚î§")
        for line in wrap_text(new_hypothesis, width-4).split('\n')[:4]:  # Show first 4 lines
            print("‚îÇ " + line.ljust(width-3) + "‚îÇ")
        if len(new_hypothesis) > width*4:
            print("‚îÇ " + "...".ljust(width-3) + "‚îÇ")
        print("‚îî" + "‚îÄ"*(width-2) + "‚îò")

    # Final summary
    print("\n" + " "*30 + "‚Üì")
    print("\n" + "‚îè" + "‚îÅ"*(width-2) + "‚îì")
    print("‚îÉ" + " ‚úÖ FINAL ANSWER (Complete Synthesis)".center(width-2) + "‚îÉ")
    print("‚î£" + "‚îÅ"*(width-2) + "‚î´")
    for line in wrap_text(hypothesis_evolution[-1], width-4).split('\n'):
        print("‚îÉ " + line.ljust(width-3) + "‚îÉ")
    print("‚îó" + "‚îÅ"*(width-2) + "‚îõ")

    # Statistics
    print("\n" + "="*width)
    print("REFINEMENT STATISTICS:")
    print("="*width)
    print(f"  Total slices processed:     {len(slices_info)}")
    print(f"  Total sub_RLM calls:        {len(slices_info) * 2} (query + refine per slice)")
    print(f"  Hypothesis versions:        {len(hypothesis_evolution)}")
    print(f"  Information sources used:   {', '.join([s[0] for s in slices_info])}")
    print("="*width)


def run_visualization_test(context, query, api_key, test_name):
    """
    Run a test and create visualization of the refinement process.
    """
    print("\n" + "="*80)
    print(f"RUNNING TEST: {test_name}")
    print("="*80)

    # Create slices
    slices = ContextSlicer.auto_slice_context(context)
    print(f"Created {len(slices)} slices: {list(slices.keys())}")

    # Initialize client
    client = AnthropicClient(api_key=api_key, model="claude-3-opus-20240229")

    # Track evolution
    hypothesis = f"Initial: Need to answer '{query}'"
    hypothesis_evolution = [hypothesis]
    slices_info = []

    print("\nProcessing slices...")
    for i, (slice_id, slice_obj) in enumerate(slices.items(), 1):
        print(f"  [{i}/{len(slices)}] {slice_id}...", end=" ")

        # Query slice
        slice_prompt = f"Based on this context, answer: {query}\n\nContext: {slice_obj.content}\n\nBe concise."
        try:
            finding = client.completion(slice_prompt)
            print(f"‚úì ({len(finding)} chars)", end=" ")
        except Exception as e:
            print(f"‚úó Error: {e}")
            continue

        # Refine hypothesis
        refinement_prompt = f"Current: {hypothesis}\n\nNew finding from {slice_id}: {finding}\n\nProvide updated hypothesis. Be concise."
        try:
            refined = client.completion(refinement_prompt)
            hypothesis = refined
            hypothesis_evolution.append(hypothesis)
            slices_info.append((slice_id, finding))
            print("‚úì Refined")
        except Exception as e:
            print(f"‚úó Error: {e}")
            continue

    # Create visualization
    print("\n" + "="*80)
    print("GENERATING VISUALIZATION...")
    print("="*80)

    create_ascii_visualization(test_name, query, slices_info, hypothesis_evolution)

    return hypothesis_evolution


def main():
    """Run visualization tests."""
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        print("‚ùå Error: ANTHROPIC_API_KEY environment variable not set")
        print("Usage: export ANTHROPIC_API_KEY=your_key && python visualize_refinement.py")
        sys.exit(1)

    # Example 1: Simple product analysis
    context1 = {
        'user_reviews': 'Users praise the intuitive interface and fast response times. Common complaints: mobile app crashes frequently, especially on iOS devices.',
        'technical_specs': 'Built with React frontend, Node.js backend. Supports 10K concurrent users. 99.5% uptime SLA. AWS infrastructure.',
        'support_tickets': 'Top issues: mobile crashes (35%), login problems (20%), slow reports (15%). Average resolution: 4 hours.'
    }

    result1 = run_visualization_test(
        context1,
        "What are the product's main strengths and weaknesses?",
        api_key,
        "Product Analysis"
    )

    print("\n\n" + "="*80)
    print("VISUALIZATION COMPLETE")
    print("="*80)
    print("\nKey Observations:")
    print("  ‚Ä¢ Each slice adds NEW information to the hypothesis")
    print("  ‚Ä¢ Hypothesis becomes MORE comprehensive with each iteration")
    print("  ‚Ä¢ Final answer SYNTHESIZES information from ALL slices")
    print("  ‚Ä¢ No single slice alone would provide the complete picture")
    print("="*80)


if __name__ == "__main__":
    main()
